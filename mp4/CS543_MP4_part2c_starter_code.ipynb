{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS543_MP4_part2c_starter_code.ipynb","provenance":[{"file_id":"1assXCSrnwBb37fbTisNRf8IuB3G-261C","timestamp":1587443213881},{"file_id":"1uxqAlJvHhJQ87yQlzLMgApUuBCfHvM_W","timestamp":1586648932535}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_2uohksRc8R6","colab_type":"code","outputId":"ca63dd0f-72d2-4861-fef2-102b719534d0","executionInfo":{"status":"error","timestamp":1588218586852,"user_tz":300,"elapsed":6872,"user":{"displayName":"Yutong Xie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXdeoCfgkQhGM6Y9yxqYJammXB7UaVouj7KqsW=s64","userId":"16538548856605091169"}},"colab":{"base_uri":"https://localhost:8080/","height":548}},"source":["# Mounting your Google Drive is optional, and you could also simply copy and\n","# upload the data to your colab instance. This manula upload is also easy to do, \n","# but you will have to figure out how to do it.\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9a9a89271754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sLFBEMfVdHId","colab_type":"code","colab":{}},"source":["import os\n","if not os.path.exists(\"/content/gdrive/My Drive/CS_543_MP4\"):\n","    os.makedirs(\"/content/gdrive/My Drive/CS_543_MP4\")\n","os.chdir(\"/content/gdrive/My Drive/CS_543_MP4\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URakNqdPk1Uq","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"geohpotit_Ek"},"source":[""]},{"cell_type":"code","metadata":{"id":"UzpXeiVddIdi","colab_type":"code","colab":{}},"source":["import glob\n","import os\n","import numpy as np\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, average_precision_score\n","\n","from PIL import Image\n","import torch\n","from torch import nn\n","from torch.utils import data\n","from torchvision.transforms import ToTensor\n","from torch.autograd import Variable\n","\n","import copy\n","import torchvision.models as models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmuN6ke4XxqU","colab_type":"code","colab":{}},"source":["torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTlJmzl7dR4_","colab_type":"code","colab":{}},"source":["DATASET_PATH = 'data/sbd/'\n","IS_GPU = True\n","TOTAL_CLASSES = 9\n","\n","class SegmentationDataset(data.Dataset):\n","    \"\"\"\n","    Data loader for the Segmentation Dataset. If data loading is a bottleneck, \n","    you may want to optimize this in for faster training. Possibilities include\n","    pre-loading all images and annotations into memory before training, so as \n","    to limit delays due to disk reads.\n","    \"\"\"\n","    def __init__(self, split=\"train\", data_dir=DATASET_PATH):\n","        assert(split in [\"train\", \"val\", \"test\"])\n","        self.img_dir = os.path.join(data_dir, split)\n","        self.classes = []\n","        with open(os.path.join(data_dir, 'classes.txt'), 'r') as f:\n","          for l in f:\n","            self.classes.append(l.rstrip())\n","        self.n_classes = len(self.classes)\n","        self.split = split\n","        self.data = glob.glob(self.img_dir + '/*.jpg') \n","        self.data = [os.path.splitext(l)[0] for l in self.data]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img = Image.open(self.data[index] + '.jpg')\n","        gt = Image.open(self.data[index] + '.png')\n","        \n","        img = ToTensor()(img)\n","        gt = torch.LongTensor(np.asarray(gt)).unsqueeze(0)\n","        return img, gt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oMHIGsCdckB","colab_type":"code","colab":{}},"source":["# #########\n","# TODO: design your own network here. The expectation is to write from scratch. But it's okay to get some inspiration \n","# from conference paper. The bottom line is that you will not just copy code from other repo\n","# #########\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","def Conv(Cin,Cout):\n","    down = nn.Sequential(   \n","        nn.Conv2d(Cin,Cout,3,padding=1,stride=1),\n","        nn.BatchNorm2d(Cout),\n","        nn.ReLU(inplace=True), \n","    )\n","    return down\n","\n","    \n","class ResNet(nn.Module):\n","\n","    def __init__(self): # feel free to modify input paramters\n","        super(ResNet, self).__init__()\n","        resnet18 = models.resnet18(pretrained=True)\n","\n","        for param in resnet18.parameters():\n","          param.requires_grad = False\n","\n","        resnet18 = list(resnet18.children())\n","        self.preprocess = Conv(3, 64)\n","        self.down0 = nn.Sequential(*resnet18[:3])\n","        self.down1 = nn.Sequential(*resnet18[3:5])\n","        self.down2 = resnet18[5]\n","        self.down3 = resnet18[6]\n","        self.down4 = resnet18[7]\n","        \n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","        self.conv1 = Conv(256 + 512, 512)\n","        self.conv2 = Conv(128 + 512, 256)\n","        self.conv3 = Conv(64 + 256, 256)\n","        self.conv4 = Conv(64 + 256, 128)\n","        self.conv5 = Conv(64 + 128, 64)\n","        self.conv6 = nn.Conv2d(64, 9, 1)\n","\n","    def forward(self, x):\n","        x_raw = self.preprocess(x)\n","\n","        x0 = self.down0(x)            \n","        x1 = self.down1(x0)\n","        x2 = self.down2(x1)\n","        x3 = self.down3(x2)        \n","        x4 = self.down4(x3)\n","        \n","        x = self.upsample(x4)\n","        x = torch.cat((x, x3), dim=1)\n","        x = self.conv1(x)\n"," \n","        x = self.upsample(x)\n","        x = torch.cat((x, x2), dim=1)\n","        x = self.conv2(x)\n","\n","        x = self.upsample(x)\n","        x = torch.cat((x, x1), dim=1)\n","        x = self.conv3(x)\n","\n","        x = self.upsample(x)\n","        x = torch.cat((x, x0), dim=1)\n","        x = self.conv4(x)\n","        \n","        x = self.upsample(x)\n","        x = torch.cat((x, x_raw), dim=1)\n","        x = self.conv5(x)        \n","        \n","        x = self.conv6(x)\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6Dtn7yudjC8","colab_type":"code","colab":{}},"source":["def segmentation_eval(gts, preds, classes, plot_file_name):\n","    \"\"\"\n","    @param    gts               numpy.ndarray   ground truth labels\n","    @param    preds             numpy.ndarray   predicted labels\n","    @param    classes           string          class names\n","    @param    plot_file_name    string          plot file names\n","    \"\"\"\n","    ious, counts = compute_confusion_matrix(gts, preds)\n","    aps = compute_ap(gts, preds)\n","    plot_results(counts, ious, aps, classes, plot_file_name)\n","    for i in range(len(classes)):\n","        print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format(classes[i], aps[i], ious[i]))\n","    print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format('mean', np.mean(aps), np.mean(ious)))\n","    return aps, ious\n","\n","def plot_results(counts, ious, aps, classes, file_name):\n","    fig, ax = plt.subplots(1,1)\n","    conf = counts / np.sum(counts, 1, keepdims=True)\n","    conf = np.concatenate([conf, np.array(aps).reshape(-1,1), \n","                           np.array(ious).reshape(-1,1)], 1)\n","    conf = conf * 100.\n","    sns.heatmap(conf, annot=True, ax=ax, fmt='3.0f') \n","    arts = [] \n","    # labels, title and ticks\n","    _ = ax.set_xlabel('Predicted labels')\n","    arts.append(_)\n","    _ = ax.set_ylabel('True labels')\n","    arts.append(_)\n","    _ = ax.set_title('Confusion Matrix, mAP: {:5.1f}, mIoU: {:5.1f}'.format(\n","      np.mean(aps)*100., np.mean(ious)*100.))\n","    arts.append(_)\n","    _ = ax.xaxis.set_ticklabels(classes + ['AP', 'IoU'], rotation=90)\n","    arts.append(_)\n","    _ = ax.yaxis.set_ticklabels(classes, rotation=0)\n","    arts.append(_)\n","    fig.savefig(file_name, bbox_inches='tight')\n","\n","def compute_ap(gts, preds):\n","    aps = []\n","    for i in range(preds.shape[1]):\n","      ap, prec, rec = calc_pr(gts == i, preds[:,i:i+1,:,:])\n","      aps.append(ap)\n","    return aps\n","\n","def calc_pr(gt, out, wt=None):\n","    gt = gt.astype(np.float64).reshape((-1,1))\n","    out = out.astype(np.float64).reshape((-1,1))\n","\n","    tog = np.concatenate([gt, out], axis=1)*1.\n","    ind = np.argsort(tog[:,1], axis=0)[::-1]\n","    tog = tog[ind,:]\n","    cumsumsortgt = np.cumsum(tog[:,0])\n","    cumsumsortwt = np.cumsum(tog[:,0]-tog[:,0]+1)\n","    prec = cumsumsortgt / cumsumsortwt\n","    rec = cumsumsortgt / np.sum(tog[:,0])\n","    ap = voc_ap(rec, prec)\n","    return ap, rec, prec\n","\n","def voc_ap(rec, prec):\n","    rec = rec.reshape((-1,1))\n","    prec = prec.reshape((-1,1))\n","    z = np.zeros((1,1)) \n","    o = np.ones((1,1))\n","    mrec = np.vstack((z, rec, o))\n","    mpre = np.vstack((z, prec, z))\n","\n","    mpre = np.maximum.accumulate(mpre[::-1])[::-1]\n","    I = np.where(mrec[1:] != mrec[0:-1])[0]+1;\n","    ap = np.sum((mrec[I] - mrec[I-1])*mpre[I])\n","    return ap\n","\n","def compute_confusion_matrix(gts, preds):\n","    preds_cls = np.argmax(preds, 1)\n","    gts = gts[:,0,:,:]\n","    conf = confusion_matrix(gts.ravel(), preds_cls.ravel())\n","    inter = np.diag(conf)\n","    union = np.sum(conf, 0) + np.sum(conf, 1) - np.diag(conf)\n","    union = np.maximum(union, 1)\n","    return inter / union, conf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeZky2AHeyec","colab_type":"code","colab":{}},"source":["# Colab has GPUs, you will have to move tensors and models to GPU.\n","device = torch.device(\"cuda:0\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUEu8F7Je27N","colab_type":"code","colab":{}},"source":["#############\n","#TODO: initialize your model \n","model = ResNet().to(device) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"okJ-P_JGesKq","colab_type":"code","colab":{}},"source":["# This is a trivial semantic segmentor. For eqch pixel location it computes the \n","# distribution of the class label in the training set and uses that as the \n","# prediction. Quite unsuprisingly it doesn't perform very well. Though we provide\n","# this code so that you can understand the data formats for the benchmarking \n","# functions.\n","def simple_train():\n","    train_dataset = SegmentationDataset(split='train')\n","    train_dataloader = data.DataLoader(train_dataset, batch_size=1, \n","                                       shuffle=True, num_workers=4, \n","                                       drop_last=True)\n","    counts = np.zeros((train_dataset.n_classes, 224, 288))\n","    N = 0\n","    for i, batch in enumerate(tqdm(train_dataloader)):\n","      img, gt = batch\n","      gt = gt.cpu().numpy()\n","      for j in range(train_dataset.n_classes):\n","          counts[j,:,:] += gt[0,0,:,:] == j\n","      N += 1\n","    model = counts / N\n","    \n","    return model\n","\n","def simple_predict(split, model):\n","    dataset = SegmentationDataset(split=split, data_dir=DATASET_PATH)\n","    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n","                                 num_workers=0, drop_last=False)\n","    gts, preds = [], []\n","    for i, batch in enumerate(tqdm(dataloader)):\n","      img, gt = batch\n","      gt = gt.cpu().numpy()\n","      gts.append(gt[0,:,:,:])\n","      preds.append(model)\n","\n","    gts = np.array(gts)\n","    preds = np.array(preds)\n","    return gts, preds, list(dataset.classes)\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtCD9BFV3uEL","colab_type":"code","colab":{}},"source":["def eval(model, data_loader, is_gpu):\n","\n","    gts, preds = [], []\n","    with torch.no_grad():\n","      for i, batch in enumerate(tqdm(dataloader)):\n","        img, gt = batch\n","        if is_gpu:\n","            img = img.cuda()\n","            \n","        outputs = model(img)\n","        gt = gt.numpy()\n","        gts.append(gt[0,:,:,:])\n","        outputs = outputs.data.cpu().numpy()\n","        preds.append(outputs[0,:,:,:])\n","\n","    gts = np.array(gts)\n","    preds = np.array(preds)\n","    return gts, preds, list(test_dataset.classes)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuC-425RNjzm","colab_type":"code","colab":{}},"source":["# Load Data\n","train_dataset = SegmentationDataset(split='train')\n","train_dataloader = data.DataLoader(train_dataset, batch_size=1, \n","                                    shuffle=True, num_workers=4, \n","                                    drop_last=True)\n","\n","dataset = SegmentationDataset(split='val', data_dir=DATASET_PATH)\n","dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n","                              num_workers=0, drop_last=False)\n","\n","test_dataset = SegmentationDataset(split='test', data_dir=DATASET_PATH)\n","test_loader = data.DataLoader(test_dataset, batch_size=1, shuffle=False, \n","                              num_workers=0, drop_last=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kt79KinxXSI1","colab_type":"code","colab":{}},"source":["# 3. Define a Loss function and optimizer\n","import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","\n","# Tune the learning rate.\n","# See whether the momentum is useful or not\n","optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n","# optimizer = optim.Adam(model.parameters(), lr=0.005)\n","plt.ioff()\n","fig = plt.figure()\n","mAP_over_epochs = []\n","mIoU_over_epochs = []\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iIIWPPS4LzN","colab_type":"code","colab":{}},"source":["########################################################################\n","# TODO: Implement your training cycles, make sure you evaluate on validation \n","# dataset and compute evaluation metrics every so often. \n","# You may also want to save models that perform well.\n","EPOCHS = 40\n","\n","def training():\n","    best_loss = 100.0\n","    for epoch in tqdm(range(EPOCHS), total=EPOCHS):\n","        running_loss = 0.0\n","        for i, data in enumerate(train_dataloader, 0):\n","          inputs, labels = data\n","          \n","          if IS_GPU:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          labels = labels.squeeze(1)\n","          # print(outputs.shape)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          # print statistics\n","          running_loss += loss.item()\n","\n","        # Normalizing the loss by the total number of train batches\n","        running_loss/=len(train_dataloader)\n","        print('Training Epoch [%d] loss: %.3f' %\n","              (epoch + 1, running_loss))\n","\n","        gts, preds, _ = eval(model, dataloader, IS_GPU)\n","\n","        ious, counts = compute_confusion_matrix(gts, preds)\n","        aps = compute_ap(gts, preds)\n","        print('Test result on Validation images:')\n","        print('{:>0s}: AP: {:0.2f}, IoU: {:0.2f}'.format('mean', np.mean(aps), np.mean(ious)))\n","\n","        if running_loss < best_loss:\n","          print(\"saving best model \\n\")\n","          best_loss = running_loss\n","          best_model_wts = copy.deepcopy(model.state_dict())\n","\n","\n","        mAP_over_epochs.append(np.mean(aps))\n","        mIoU_over_epochs.append(np.mean(ious))\n","    # -----------------------------\n","\n","    # Plot train loss over epochs and val set accuracy over epochs\n","    # Nothing to change here\n","    # -------------\n","    plt.subplot(2, 1, 1)\n","    plt.ylabel('mAP')\n","    plt.plot(np.arange(EPOCHS), mAP_over_epochs, 'k-')\n","    plt.title('mAP and mIoU')\n","    plt.xticks(np.arange(EPOCHS, dtype=int))\n","    plt.grid(True)\n","\n","    plt.subplot(2, 1, 2)\n","    plt.plot(np.arange(EPOCHS), mIoU_over_epochs, 'b-')\n","    plt.ylabel('mIoU')\n","    plt.xlabel('Epochs')\n","    plt.xticks(np.arange(EPOCHS, dtype=int))\n","    plt.grid(True)\n","    plt.savefig(\"plotq2.png\")\n","    plt.close(fig)\n","    print('Finished Training')\n","    # -------------\n","\n","    model.load_state_dict(best_model_wts)\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HA9WZ-Nqh1Ka","colab_type":"code","colab":{}},"source":["# ########################################################################\n","# # TODO: Evaluate your result, and report Mean average precision on test dataset \n","# # using provided helper function. Here we show how we can train and evaluate the \n","# # simple model that we provided on the validation set. You will want to report\n","# # performance on the validation set for the variants you tried, and the \n","# # performance of the final model on the test set.\n","\n","best_model = training() \n","gts, preds, classes  = eval(best_model, test_loader, IS_GPU)\n","aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXGQ91hnEK-2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xm_8iaL3ENah","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}